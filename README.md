# ğŸš€ Client Sales Data Automation & Analysis

## ğŸ“Œ Table of Contents
- [Project Overview](#project-overview)
- [Repository Structure](#repository-structure)
- [Setup & Environment Configuration](#setup--environment-configuration)
- [Implemented Features](#implemented-features)
- [Detailed Workflow Summary](#detailed-workflow-summary)
- [Key Learnings](#key-learnings)
- [Next Steps](#next-steps)
- [How to Run](#how-to-run)
- [Contributing](#contributing)

---

## ğŸš€ Project Overview

This repository showcases a comprehensive, production-ready workflow designed to automate, validate, and analyze client sales data using **Python, NumPy, Pandas, Great Expectations, and Git**.

It includes:

1. **NumPy-powered statistical sales analysis.**
2. **Dynamic discount calculations using broadcasting.**
3. **ETL scripts for dataset merging and cleaning.**
4. **Advanced exception handling.**
5. **File automation scripts (renaming, sorting).**
6. **Great Expectations integration for robust data validation.**
7. **Systematic version control with feature branches, rebasing, and clean commit histories.**
8. **Professional documentation, PEP-8 compliance, and polished LinkedIn updates.**

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ venv/                      # Virtual environment (excluded from Git)
â”œâ”€â”€ data/                      # Contains all datasets and CSV files
â”‚   â””â”€â”€ sales_dataset_1.csv
â”‚   â””â”€â”€ sales_dataset_2.csv
â”‚   â””â”€â”€ sales_dataset_3.csv
â”‚   â””â”€â”€ merged_sales_data.csv
â”œâ”€â”€ scripts/                   # All Python scripts neatly organized
â”‚   â””â”€â”€ client_inventory.py
â”‚   â””â”€â”€ numpy_discount_calc.py
â”‚   â””â”€â”€ sales_analysis.py
â”‚   â””â”€â”€ data_merge.py
â”‚   â””â”€â”€ file_automation.py
â”‚   â””â”€â”€ list_dict_practice.py
â”‚   â””â”€â”€ exception_practice.py
â”‚   â””â”€â”€ broadcasting_exercise_01.py - broadcasting_exercise_10.py
â”‚   â””â”€â”€ user_info_formatter.py
â”œâ”€â”€ great_expectations/        # Great Expectations project directory
â”œâ”€â”€ day1_plan.md               # Task scope & plan documentation
â””â”€â”€ .gitignore                 # Excludes venv/, __pycache__/, datasets, exports
```

---

## âš™ï¸ Setup & Environment Configuration

This environment was built for **scalability, maintainability, and production-level standards**. Here's how to replicate and configure it:

### ğŸ“¦ Dependencies

- **Python 3.10+**
- `numpy`
- `pandas`
- `great_expectations`
- `python-dotenv` (optional)
- `pytest` (optional)

### ğŸ–¥ Installation Instructions

```bash
# 1ï¸âƒ£ Clone the repository
git clone <your-repo-link>
cd <repo-name>

# 2ï¸âƒ£ Set up a virtual environment
python -m venv venv
# Activate virtual environment:
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# 3ï¸âƒ£ Upgrade pip & install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# If requirements.txt not available:
pip install numpy pandas great_expectations python-dotenv pytest
```

---

## âœ¨ Implemented Features

âœ… **Professional Repo Structure**  
Scripts, datasets, configs clearly separated.

âœ… **Feature Branch Workflow**  
All new functionality developed in dedicated branches, tested, cleanly merged.

âœ… **NumPy Automation Scripts**  
Efficient sales analysis, statistical operations, discount calculations â€” **no loops**, full broadcasting.

âœ… **ETL Data Merging**  
Sales CSVs consolidated using Pandas, validated via Great Expectations.

âœ… **Advanced Exception Handling**  
Deliberate edge cases tested, with robust try-except blocks across critical scripts.

âœ… **File Automation**  
Scripts for renaming, categorizing, and sorting files via `os` and `shutil`.

âœ… **PEP-8 Compliance & Modularity**  
All code follows clean standards, modular functions, clear docstrings.

âœ… **Great Expectations Integration**  
Expectation suites programmatically defined, validating merged datasets before export.

âœ… **Public Branding**  
Regular, polished LinkedIn updates, clean visuals, clear progress logs.

---

## ğŸ“‹ Detailed Workflow Summary

### **ğŸ“… Day 1-2: Foundation Setup**
- Downloaded latest Python version, verified installation.
- Installed and configured **VS Code**.
- Completed **Codecademy** foundational exercises: print statements, variables, arithmetic, f-strings, loops, control flow.
- Scripts organized into descriptive files: `lesson1_print_statements.py`, `lesson2_variables.py`.
- Began structured note-taking (variables, conditionals, data types).
- Completed **Exercism** exercises focusing on arithmetic, type conversions, and `raise` statement error handling.
- Created, debugged, and uploaded `client_inventory.py`, using loops, control flow, and PEP-8 standards to GitHub.

### **ğŸ“… Day 3-4: NumPy Mastery**
- Set up dedicated branch: `day-3-numpy-intro`.
- Completed 15+ NumPy exercises covering:
  - Array creation, reshaping, advanced indexing.
  - Broadcasting, vectorized calculations, masking.
- Built `sales_analysis.py`: automated client sales summary (total, average, std, min/max) â†’ output to Pandas DataFrame and CSV.
- Developed `numpy_discount_calc.py`: dynamic discount application without loops.
- Rigorous Git feature branching, commits, and clean merges.

### **ğŸ“… Day 5: Broadcasting & Exception Handling**
- Completed 10 advanced Kaggle broadcasting exercises.
- Embedded robust `try-except` blocks in `numpy_discount_calc.py` and related scripts.
- Created intentional Git conflicts, resolved and documented them.
- Finalized feature branch, merged, shared progress on LinkedIn with visuals.

### **ğŸ“… Day 6: File Automation Focus**
- Objective set in `Notion`.
- Built `file_automation.py` using `os` and `shutil`:
  - File renaming.
  - Categorizing by extensions (.pdf, .csv, .jpg).
  - Exception handling for missing files, permission issues.
- Extensive dummy file testing.
- Documented, committed, merged into main.
- LinkedIn post shared with clear visuals, encouraging feedback.

### **ğŸ“… Day 7: Refactoring & Git Mastery**
- Refactored all major scripts:
  - Modular functions.
  - Clean docstrings.
  - PEP-8 compliance.
- Mastered **Git rebasing, squashing**, cleaned commit histories.
- Enhanced README files with clear setup instructions.
- Polished LinkedIn post with Canva visual showcasing automation work.

### **ğŸ“… Week 2, Day 1: Data Merging & Validation**
- Reorganized GitHub repo:
  - `/scripts` â†’ All scripts.
  - `/data` â†’ All datasets.
- Created `feature/data-merge` branch.
- Developed `data_merge.py` merging three sales CSVs.
- Set up **virtual environment**, installed:
  - Pandas, Great Expectations.
- Initialized **Great Expectations project**, programmatically defined expectation suites.
- Verified merged dataset quality, exported to `sales_consolidated.csv`.
- Documented everything in `README.md`, clear commit history maintained.

---

## ğŸ“š Key Learnings

1. **NumPy Broadcasting & Vectorized Computation**:  
Efficient large-scale data manipulation without loops.

2. **Professional Git Workflow**:  
Branching, merging, rebasing, squashing â€” all used to maintain clean histories.

3. **Data Validation Discipline**:  
Applied Great Expectations to enforce data quality checks programmatically.

4. **Exception Handling Best Practices**:  
Integrated and tested exception handling under various scenarios.

5. **File Automation & Real-World ETL**:  
Built scalable scripts automating file operations, dataset merges, and exports.

6. **PEP-8 Compliance & Documentation**:  
Maintained high code standards, docstrings, modular functions, clear comments.

7. **Public Portfolio Development**:  
Shared polished, methodical progress updates on LinkedIn, building strong branding.

---

## ğŸš€ Next Steps

- Integrate **Matplotlib/Seaborn** for sales trend visualizations.
- Expand ETL pipelines to pull real-world APIs/datasets.
- Add **pytest** unit tests across key scripts.
- Experiment with **NumPy-based machine learning models**.
- Package scripts into a deployable solution (CLI or web interface).

---

## ğŸ›  How to Run

```bash
# Clone repo
git clone <your-repo-link>
cd <repo-name>

# Set up virtual environment
python -m venv venv
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run key scripts:
python scripts/sales_analysis.py
python scripts/numpy_discount_calc.py
python scripts/data_merge.py
python scripts/file_automation.py

# Run Great Expectations data validation
great_expectations checkpoint run sales_data_checkpoint
```

---

## ğŸ¤ Contributing

Contributions, suggestions, and constructive feedback are welcome.  
Feel free to fork, submit pull requests, or reach out via [LinkedIn](www.linkedin.com/in/ivan-k-573b74330).

---
```
